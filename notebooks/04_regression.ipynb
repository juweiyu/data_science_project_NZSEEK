{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_regression.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUtUNlTsFKyB"
      },
      "source": [
        "# import\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsqT30EYGo-Q"
      },
      "source": [
        "# **--------------------------PREPARE THE DATA--------------------------**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWQT095_HEUr"
      },
      "source": [
        "1. **Load df**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "he284HtLAES-"
      },
      "source": [
        "import io\n",
        "df_admin = pd.read_excel('/content/Cleaned_NZ_Admin_JOBS.xlsx')\n",
        "df_banking = pd.read_excel('/content/Cleaned_NZ_Banking_JOBS.xlsx')\n",
        "df_ceo = pd.read_excel('/content/Cleaned_NZ_CEO_JOBS.xlsx')\n",
        "# Dataset is now stored in a Pandas Dataframe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2MQDWy_HJg1"
      },
      "source": [
        "2. **Add domain for regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Q3FdR5_170N"
      },
      "source": [
        "df_admin['Domain'] = 'Admin'\n",
        "df_banking['Domain'] = 'Banking'\n",
        "df_ceo['Domain'] = 'CEO'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "id": "aXO8mLm9D-Yy",
        "outputId": "2fe871e6-d339-4510-e496-76c9dda7b2ce"
      },
      "source": [
        "# Combine three dataframes\n",
        "df_all = pd.concat([df_admin, df_banking, df_ceo], ignore_index=True, sort=False)\n",
        "df_all = df_all[[\"Job\", \"Company\", \"Region\", \"City\", \"Lowest Salary\", \"Higest Salary\", \"Posted Date (Days Ago)\", \"Domain\"]]\n",
        "df_all = df_all.dropna()\n",
        "df_all.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Job</th>\n",
              "      <th>Company</th>\n",
              "      <th>Region</th>\n",
              "      <th>City</th>\n",
              "      <th>Lowest Salary</th>\n",
              "      <th>Higest Salary</th>\n",
              "      <th>Posted Date (Days Ago)</th>\n",
              "      <th>Domain</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Administrator</td>\n",
              "      <td>Private Advertiser</td>\n",
              "      <td>Bay of Plenty</td>\n",
              "      <td>Tauranga</td>\n",
              "      <td>44469</td>\n",
              "      <td>49720</td>\n",
              "      <td>0</td>\n",
              "      <td>Admin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Receptionist</td>\n",
              "      <td>Avenues Orthodontics</td>\n",
              "      <td>Bay of Plenty</td>\n",
              "      <td>Tauranga</td>\n",
              "      <td>45928</td>\n",
              "      <td>46805</td>\n",
              "      <td>0</td>\n",
              "      <td>Admin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Prosecutions Support Officer</td>\n",
              "      <td>New Zealand Police</td>\n",
              "      <td>Auckland</td>\n",
              "      <td>NO DATA</td>\n",
              "      <td>38776</td>\n",
              "      <td>44341</td>\n",
              "      <td>4</td>\n",
              "      <td>Admin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Early Childhood Centre Administrator</td>\n",
              "      <td>Kew Pacific Island Early Learning Centre</td>\n",
              "      <td>Southland</td>\n",
              "      <td>Invercargill</td>\n",
              "      <td>54903</td>\n",
              "      <td>54961</td>\n",
              "      <td>0</td>\n",
              "      <td>Admin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Business Support Administrator</td>\n",
              "      <td>Private Advertiser</td>\n",
              "      <td>Canterbury</td>\n",
              "      <td>Christchurch</td>\n",
              "      <td>50095</td>\n",
              "      <td>50788</td>\n",
              "      <td>4</td>\n",
              "      <td>Admin</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    Job  ... Domain\n",
              "0                         Administrator  ...  Admin\n",
              "1                          Receptionist  ...  Admin\n",
              "2          Prosecutions Support Officer  ...  Admin\n",
              "3  Early Childhood Centre Administrator  ...  Admin\n",
              "4        Business Support Administrator  ...  Admin\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Oq_VTN_HdJI"
      },
      "source": [
        "3. **Set y_df to lower_salary (regression goal)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hxS-9Ym3eAY"
      },
      "source": [
        "y_df = df_all['Lowest Salary']\n",
        "y_df_encoded = LabelEncoder().fit_transform(y_df.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJnl-c3iHkka"
      },
      "source": [
        "4. **Encode x_label** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "Plsq_f7SE9vk",
        "outputId": "7d457b5a-ed73-497a-ab76-958a4f101787"
      },
      "source": [
        "x_df = df_all.apply(LabelEncoder().fit_transform)\n",
        "x_df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Job</th>\n",
              "      <th>Company</th>\n",
              "      <th>Region</th>\n",
              "      <th>City</th>\n",
              "      <th>Lowest Salary</th>\n",
              "      <th>Higest Salary</th>\n",
              "      <th>Posted Date (Days Ago)</th>\n",
              "      <th>Domain</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>49</td>\n",
              "      <td>411</td>\n",
              "      <td>1</td>\n",
              "      <td>34</td>\n",
              "      <td>1169</td>\n",
              "      <td>984</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>647</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "      <td>34</td>\n",
              "      <td>1368</td>\n",
              "      <td>584</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>635</td>\n",
              "      <td>361</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>492</td>\n",
              "      <td>359</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>304</td>\n",
              "      <td>282</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>2435</td>\n",
              "      <td>2304</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>132</td>\n",
              "      <td>411</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1887</td>\n",
              "      <td>1161</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Job  Company  Region  ...  Higest Salary  Posted Date (Days Ago)  Domain\n",
              "0   49      411       1  ...            984                       0       0\n",
              "1  647       47       1  ...            584                       0       0\n",
              "2  635      361       0  ...            359                       4       0\n",
              "3  304      282       9  ...           2304                       0       0\n",
              "4  132      411       2  ...           1161                       4       0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkCdGkAQIDmC"
      },
      "source": [
        "5. **Perform train-test split**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gAZD9kiFTAQ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_df, y_df, test_size=0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "av1SIFHlk9fo"
      },
      "source": [
        "# **--------------------------EVALUATION FUNCTIONS---------------------**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AK4XmmRVIsEk"
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def cross_val(model):\n",
        "    pred = cross_val_score(model, x_df, y_df, cv=5, scoring='r2')\n",
        "    return pred\n",
        "\n",
        "def print_evaluate(true, predicted):  \n",
        "    mae = metrics.mean_absolute_error(true, predicted)\n",
        "    mse = metrics.mean_squared_error(true, predicted)\n",
        "    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n",
        "    r2_square = metrics.r2_score(true, predicted)\n",
        "    print('MAE:', mae)\n",
        "    print('MSE:', mse)\n",
        "    print('RMSE:', rmse)\n",
        "    print('R2 Square', r2_square)\n",
        "    \n",
        "def evaluate(true, predicted):\n",
        "    mae = metrics.mean_absolute_error(true, predicted)\n",
        "    mse = metrics.mean_squared_error(true, predicted)\n",
        "    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n",
        "    r2_square = metrics.r2_score(true, predicted)\n",
        "    return mae, mse, rmse, r2_square"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36GislRiIZ9Q"
      },
      "source": [
        "# **-----------------------------REGRESSION WITH XGBOOST-----------------------------**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZlqDdBTkaVr"
      },
      "source": [
        "### **Define a XGBOOST regressor**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnFhy2yjFUhl",
        "outputId": "f8f1af58-71f6-4ef8-b462-6f0b4b1ead20"
      },
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "xgb_model = xgb.XGBRegressor()\n",
        "\n",
        "params = {\n",
        "    \"learning_rate\": uniform(0.01, 0.3), \n",
        "    \"max_depth\": randint(2, 6),\n",
        "    \"n_estimators\": randint(100, 1000), \n",
        "    \"subsample\": uniform(0.6, 1)\n",
        "}\n",
        "\n",
        "search = RandomizedSearchCV(xgb_model, param_distributions=params, random_state=12, n_iter=200, cv=3, verbose=1, n_jobs=10, return_train_score=False)\n",
        "\n",
        "search.fit(x_df, y_df_encoded)\n",
        "\n",
        "search.cv_results_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
            "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:   11.8s\n",
            "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:  1.7min\n",
            "[Parallel(n_jobs=10)]: Done 430 tasks      | elapsed:  3.6min\n",
            "[Parallel(n_jobs=10)]: Done 600 out of 600 | elapsed:  5.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[23:58:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([8.55018028e+00, 8.74795914e-02, 1.02939129e-01, 4.97353872e-02,\n",
              "        8.16282423e+00, 2.90916761e-02, 2.45021184e-02, 1.55784276e+01,\n",
              "        1.81858540e-02, 2.83873081e-02, 1.01936402e+01, 2.56142616e-02,\n",
              "        2.78911591e-02, 2.78515021e-02, 1.84773604e-02, 2.34005020e+01,\n",
              "        4.15508223e+00, 1.46121874e+01, 9.56305170e+00, 1.49386447e+01,\n",
              "        1.21495393e+01, 2.22650369e-02, 1.46865845e-02, 1.26350859e+01,\n",
              "        2.85478433e-02, 1.97610855e-02, 1.05671899e+01, 2.83073584e-02,\n",
              "        6.61967580e+00, 2.65688896e-02, 2.73825328e-02, 3.08005810e-02,\n",
              "        2.72929668e-02, 2.78191566e-02, 1.55101293e+01, 1.75764403e+01,\n",
              "        2.70187855e-02, 2.79378096e-02, 6.30962809e+00, 1.95638084e+01,\n",
              "        2.65362556e+01, 6.33363040e+00, 2.70428658e-02, 7.52412478e+00,\n",
              "        1.29882324e+01, 8.55886102e+00, 2.29095052e+01, 2.67393589e-02,\n",
              "        2.72049904e-02, 2.48877207e-02, 2.58673032e-02, 2.42065589e-02,\n",
              "        2.46316592e-02, 2.71044572e-02, 2.73285532e+00, 2.50473022e-02,\n",
              "        8.29672066e+00, 2.77365049e-02, 2.87783146e-02, 1.44466959e+01,\n",
              "        2.31688817e-02, 2.81613668e-02, 1.25521970e+01, 2.56249110e-02,\n",
              "        3.32544645e-02, 2.73942153e-02, 1.88454139e+01, 7.06867719e+00,\n",
              "        2.40437190e-02, 2.24508444e-02, 2.10076173e-02, 2.79958248e-02,\n",
              "        2.55546570e-02, 2.44865417e-02, 1.31155237e+01, 2.45932738e-02,\n",
              "        1.14351768e+01, 2.09133625e-02, 1.35729861e+01, 4.29875286e+00,\n",
              "        3.27256815e+00, 2.78461564e+01, 7.19876289e+00, 2.54596869e-02,\n",
              "        2.44236583e+01, 3.27518074e+00, 2.32481162e-02, 2.80475616e-02,\n",
              "        2.49160131e-02, 2.88938681e-02, 7.92497587e+00, 2.88298130e-02,\n",
              "        2.58452098e-02, 1.15805209e+01, 8.99120164e+00, 2.52865156e-02,\n",
              "        2.56126722e-02, 1.99613324e+01, 2.34889984e-02, 1.81909402e-02,\n",
              "        3.02212238e-02, 2.20895608e-02, 2.21914450e-02, 9.95012244e+00,\n",
              "        2.17602253e-02, 2.87253994e+01, 2.30744680e-02, 1.67841311e+01,\n",
              "        1.82152739e+01, 2.11830316e+01, 2.31365363e-02, 2.75990168e-02,\n",
              "        2.63596376e-02, 7.49426111e+00, 2.76815891e-02, 1.23253655e+01,\n",
              "        1.83388392e-02, 2.48231093e-02, 1.97209517e-02, 2.57716211e+00,\n",
              "        2.05903053e-02, 6.97175821e+00, 2.19119390e-02, 8.72439249e+00,\n",
              "        1.90792084e-02, 1.14297733e+01, 1.09614344e+01, 1.86012586e-02,\n",
              "        2.87988276e+01, 2.18390624e-02, 2.66287327e-02, 2.28056908e-02,\n",
              "        2.39002705e-02, 2.28943825e-02, 2.81404654e-02, 2.87451744e-02,\n",
              "        2.37099330e-02, 2.35923131e-02, 2.49061584e-02, 2.73530483e-02,\n",
              "        2.42530505e-02, 2.11983522e-02, 1.67532054e+01, 1.34406840e+01,\n",
              "        2.40627925e-02, 2.80142625e-02, 2.08153725e-02, 2.80338128e-02,\n",
              "        1.32907077e+01, 1.38220157e+01, 2.86739667e-02, 2.03221639e-02,\n",
              "        3.31613882e+00, 4.83911363e+00, 2.40981579e-02, 2.00597445e-02,\n",
              "        2.64764667e+01, 5.94913507e+00, 1.41042463e+01, 2.80119578e-02,\n",
              "        1.22552908e+01, 4.45347198e+00, 1.01360559e+01, 2.75340080e-02,\n",
              "        1.33787551e+01, 1.69932082e+01, 1.53825963e+01, 2.48125394e-02,\n",
              "        2.74902980e-02, 3.97957277e+00, 2.69519488e-02, 6.15690184e+00,\n",
              "        2.19598611e-02, 2.20045249e-02, 2.75487105e-02, 2.99382210e-02,\n",
              "        1.27205350e+01, 1.38936971e+01, 2.49982675e-02, 2.69415379e-02,\n",
              "        2.83258756e-02, 1.53759715e+01, 2.49723593e-02, 2.85773277e-02,\n",
              "        1.49705958e+01, 2.57538954e-02, 1.83698336e-02, 2.28665670e-02,\n",
              "        1.92250411e-02, 2.02928384e-02, 2.13381449e-02, 8.52368013e+00,\n",
              "        2.01648076e-02, 2.32689444e+01, 2.32770549e+01, 2.21199989e-02,\n",
              "        1.45097574e-02, 1.32842599e+01, 9.86633404e+00, 1.92423662e-02]),\n",
              " 'mean_score_time': array([0.17969402, 0.        , 0.        , 0.        , 0.15912938,\n",
              "        0.        , 0.        , 0.3107446 , 0.        , 0.        ,\n",
              "        0.18222427, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.66342251, 0.08666102, 0.28916518, 0.17174498, 0.36338162,\n",
              "        0.22723754, 0.        , 0.        , 0.26381866, 0.        ,\n",
              "        0.        , 0.1947426 , 0.        , 0.12527593, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.33515231,\n",
              "        0.38384827, 0.        , 0.        , 0.10654314, 0.48891211,\n",
              "        0.79211783, 0.11873603, 0.        , 0.16689603, 0.28137406,\n",
              "        0.15618944, 0.61936434, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.04738116,\n",
              "        0.        , 0.16221778, 0.        , 0.        , 0.37946502,\n",
              "        0.        , 0.        , 0.30933555, 0.        , 0.        ,\n",
              "        0.        , 0.4799753 , 0.15930915, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.32112686,\n",
              "        0.        , 0.24097514, 0.        , 0.2966795 , 0.09366568,\n",
              "        0.07534877, 0.80796186, 0.12649298, 0.        , 0.70454176,\n",
              "        0.08091696, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.14620296, 0.        , 0.        , 0.22729397, 0.15505195,\n",
              "        0.        , 0.        , 0.49302975, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.15579057, 0.        ,\n",
              "        0.81139628, 0.        , 0.3466444 , 0.40240852, 0.5455691 ,\n",
              "        0.        , 0.        , 0.        , 0.14032666, 0.        ,\n",
              "        0.20732029, 0.        , 0.        , 0.        , 0.05367327,\n",
              "        0.        , 0.15244603, 0.        , 0.17948739, 0.        ,\n",
              "        0.22385049, 0.26819166, 0.        , 0.87077125, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.45083499, 0.24462382, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.2531968 , 0.35592182,\n",
              "        0.        , 0.        , 0.07384475, 0.08554363, 0.        ,\n",
              "        0.        , 0.75043368, 0.11215734, 0.31012162, 0.        ,\n",
              "        0.25597692, 0.08282685, 0.24388178, 0.        , 0.26129492,\n",
              "        0.45863605, 0.41246573, 0.        , 0.        , 0.08969744,\n",
              "        0.        , 0.11898796, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.26978302, 0.29939095, 0.        , 0.        ,\n",
              "        0.        , 0.40475329, 0.        , 0.        , 0.33773661,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.19751104, 0.        , 0.51392031, 0.2822024 ,\n",
              "        0.        , 0.        , 0.30533576, 0.12262257, 0.        ]),\n",
              " 'mean_test_score': array([0.9843482 ,        nan,        nan,        nan, 0.98619855,\n",
              "               nan,        nan, 0.98283099,        nan,        nan,\n",
              "        0.98175137,        nan,        nan,        nan,        nan,\n",
              "        0.98431173, 0.98560198, 0.98488805, 0.97860603, 0.98686482,\n",
              "        0.98354989,        nan,        nan, 0.98523365,        nan,\n",
              "               nan, 0.98645347,        nan, 0.98366878,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.98581732,\n",
              "        0.98527535,        nan,        nan, 0.98177224, 0.9838015 ,\n",
              "        0.98433595, 0.98361823,        nan, 0.98439354, 0.98413054,\n",
              "        0.97341118, 0.98356413,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97754838,\n",
              "               nan, 0.98220965,        nan,        nan, 0.98593801,\n",
              "               nan,        nan, 0.98374489,        nan,        nan,\n",
              "               nan, 0.98706375, 0.98625095,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.98441715,\n",
              "               nan, 0.98396875,        nan, 0.98290091, 0.98456245,\n",
              "        0.9865423 , 0.98451125, 0.98424108,        nan, 0.98621247,\n",
              "        0.98367677,        nan,        nan,        nan,        nan,\n",
              "        0.97249663,        nan,        nan, 0.98367806, 0.98367358,\n",
              "               nan,        nan, 0.98421272,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97933946,        nan,\n",
              "        0.98426404,        nan, 0.98196695, 0.97648758, 0.98456967,\n",
              "               nan,        nan,        nan, 0.98179469,        nan,\n",
              "        0.97653678,        nan,        nan,        nan, 0.98432731,\n",
              "               nan, 0.98301215,        nan, 0.98472762,        nan,\n",
              "        0.98038035, 0.98525589,        nan, 0.9862419 ,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.98410502, 0.98373294,        nan,\n",
              "               nan,        nan,        nan, 0.98237053, 0.98670552,\n",
              "               nan,        nan, 0.98418133, 0.98362247,        nan,\n",
              "               nan, 0.98593683, 0.98619282, 0.97907156,        nan,\n",
              "        0.98462135, 0.98258963, 0.9863631 ,        nan, 0.98400485,\n",
              "        0.98609616, 0.98429618,        nan,        nan, 0.98392454,\n",
              "               nan, 0.9807716 ,        nan,        nan,        nan,\n",
              "               nan, 0.98416393, 0.97810224,        nan,        nan,\n",
              "               nan, 0.98573161,        nan,        nan, 0.98417759,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.98720257,        nan, 0.98405157, 0.98457473,\n",
              "               nan,        nan, 0.98393835, 0.98103745,        nan]),\n",
              " 'param_learning_rate': masked_array(data=[0.05624885271390171, 0.17012181801408932,\n",
              "                    0.28021445623510366, 0.05116279640682293,\n",
              "                    0.29326754081591266, 0.16636780816608787,\n",
              "                    0.2404402462193267, 0.01624293938561985,\n",
              "                    0.10296927534700877, 0.25485048941380806,\n",
              "                    0.2207867065765739, 0.30341742370495567,\n",
              "                    0.2402426951861466, 0.14539252342639428,\n",
              "                    0.06326925278136679, 0.13721573396529962,\n",
              "                    0.1496524300517533, 0.22975620944258504,\n",
              "                    0.10005101794719597, 0.16697382123348756,\n",
              "                    0.1817213546588828, 0.09313516432755886,\n",
              "                    0.16196682270042845, 0.19173330794067547,\n",
              "                    0.18755304773549927, 0.23846197427839794,\n",
              "                    0.2963473340837451, 0.17882114769884433,\n",
              "                    0.09453584743514067, 0.04881768730165729,\n",
              "                    0.13178750288789282, 0.21667829980973727,\n",
              "                    0.28595946128869704, 0.12556509407292224,\n",
              "                    0.18988575651920134, 0.2502202702646582,\n",
              "                    0.07318229165586516, 0.2755533083298385,\n",
              "                    0.20438775200177842, 0.2435420301578034,\n",
              "                    0.13077674436878944, 0.042845626399455654,\n",
              "                    0.19150161710906907, 0.2078427861522449,\n",
              "                    0.11041722324303177, 0.01313152062841634,\n",
              "                    0.10470047107859964, 0.2657119887394419,\n",
              "                    0.28385378962223595, 0.2026547894084684,\n",
              "                    0.05476710558031997, 0.058771566247555376,\n",
              "                    0.2993998883890621, 0.2846892586648913,\n",
              "                    0.061123509444032775, 0.08398044343692729,\n",
              "                    0.038641076039461375, 0.3013975881782734,\n",
              "                    0.1653067885106405, 0.2865477864051653,\n",
              "                    0.24248206463041871, 0.1863659454134808,\n",
              "                    0.1989549936853421, 0.20167392077864724,\n",
              "                    0.13734554166326585, 0.30978209864327283,\n",
              "                    0.30447626640809106, 0.2339328283672442,\n",
              "                    0.16657080260714682, 0.18346515174288117,\n",
              "                    0.24267118866382742, 0.06812137782230138,\n",
              "                    0.10947340788886893, 0.09751567743649978,\n",
              "                    0.23412719080414388, 0.23724211468143708,\n",
              "                    0.21066710448081444, 0.1886447882845755,\n",
              "                    0.035331342419122704, 0.11006834866486966,\n",
              "                    0.16577464142940812, 0.1959798946951073,\n",
              "                    0.18078506721720575, 0.12214258525865122,\n",
              "                    0.11753928621543272, 0.16280877155738682,\n",
              "                    0.14001506411569092, 0.2799671419791405,\n",
              "                    0.17143062341398188, 0.07989278286768985,\n",
              "                    0.19160358587677231, 0.28163078643248757,\n",
              "                    0.08376821318485123, 0.12344741145434736,\n",
              "                    0.1960012039852051, 0.2948802497596223,\n",
              "                    0.0389948574639607, 0.04205225304318569,\n",
              "                    0.18546066844878062, 0.2847561207409351,\n",
              "                    0.10472024653247086, 0.08943552808187304,\n",
              "                    0.01640928407250194, 0.014528841645520565,\n",
              "                    0.0464415134893934, 0.148615110878552,\n",
              "                    0.268723047435508, 0.21590640977167844,\n",
              "                    0.2633051778332585, 0.07529742861844314,\n",
              "                    0.2518882077006919, 0.2140731321521565,\n",
              "                    0.061999311954761785, 0.08073960117229936,\n",
              "                    0.0629416985245142, 0.012764291154257059,\n",
              "                    0.29842454344375124, 0.12731076484207993,\n",
              "                    0.2376838934371285, 0.21029726316378608,\n",
              "                    0.09932693838735088, 0.30963712266239174,\n",
              "                    0.3067231751139785, 0.21124051782815792,\n",
              "                    0.17294892106120638, 0.2681088847920134,\n",
              "                    0.07244836588740568, 0.2937184960719834,\n",
              "                    0.0930446196800168, 0.24444283013583748,\n",
              "                    0.039937995385447046, 0.09515783134700735,\n",
              "                    0.26740379161352534, 0.2547614627866196,\n",
              "                    0.04756668042767664, 0.2916251936998579,\n",
              "                    0.2539406776172024, 0.059734107327166365,\n",
              "                    0.27919948090849256, 0.2741650905483195,\n",
              "                    0.18975419418408254, 0.09447708087862662,\n",
              "                    0.24634525135233942, 0.05756507063771404,\n",
              "                    0.29075005729710646, 0.21801854145736407,\n",
              "                    0.2799736624316611, 0.28167694821880307,\n",
              "                    0.1283214484398384, 0.2484051354086793,\n",
              "                    0.2505509857221751, 0.23458353417705205,\n",
              "                    0.19123275845420215, 0.058465285989949545,\n",
              "                    0.04646169458026819, 0.11374775126970887,\n",
              "                    0.029700205794900215, 0.250506435172427,\n",
              "                    0.010766258943719789, 0.27237623921442594,\n",
              "                    0.16507052034483924, 0.11288792118523072,\n",
              "                    0.2026206671181647, 0.17173595814417605,\n",
              "                    0.09455643649209249, 0.08714651397562918,\n",
              "                    0.16694557398373805, 0.23525633817775207,\n",
              "                    0.23378527332498122, 0.06056764548426611,\n",
              "                    0.025721274115610614, 0.0969379750100206,\n",
              "                    0.10879062168130534, 0.15114913326268967,\n",
              "                    0.20870098040549637, 0.034264304999870446,\n",
              "                    0.086986052230001, 0.23488056570003696,\n",
              "                    0.08193274577359866, 0.18406346426566375,\n",
              "                    0.03886931172759205, 0.05206557547946401,\n",
              "                    0.14469530951761306, 0.12932248062620433,\n",
              "                    0.07803716414192535, 0.19655080977049633,\n",
              "                    0.2943313489749759, 0.15329927673157298,\n",
              "                    0.08923074824717338, 0.27527398830818844,\n",
              "                    0.2791045112137521, 0.0989510082720107,\n",
              "                    0.22777447083744493, 0.12934457973676097,\n",
              "                    0.1934176541112144, 0.23032246391680541,\n",
              "                    0.08905113900626711, 0.03746859569921888,\n",
              "                    0.048015082605498687, 0.2995100961952648],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_max_depth': masked_array(data=[4, 2, 3, 2, 3, 4, 4, 3, 5, 3, 2, 3, 5, 4, 4, 5, 3, 2,\n",
              "                    2, 4, 2, 3, 5, 3, 2, 5, 2, 4, 2, 2, 4, 3, 2, 3, 3, 3,\n",
              "                    2, 4, 2, 4, 5, 3, 4, 5, 3, 5, 4, 5, 2, 5, 3, 5, 5, 2,\n",
              "                    2, 4, 3, 5, 4, 5, 5, 2, 4, 4, 3, 3, 4, 5, 3, 2, 2, 2,\n",
              "                    3, 4, 5, 2, 3, 5, 3, 5, 4, 5, 2, 4, 5, 3, 3, 2, 4, 3,\n",
              "                    2, 3, 5, 3, 2, 2, 3, 4, 5, 3, 5, 3, 4, 2, 2, 5, 2, 3,\n",
              "                    3, 4, 2, 5, 2, 2, 5, 3, 3, 4, 4, 3, 5, 4, 3, 3, 5, 2,\n",
              "                    4, 2, 5, 5, 2, 5, 3, 5, 4, 5, 2, 5, 2, 5, 5, 4, 5, 2,\n",
              "                    2, 3, 4, 4, 2, 4, 4, 4, 5, 2, 2, 3, 5, 2, 4, 5, 2, 2,\n",
              "                    5, 3, 2, 5, 5, 4, 3, 4, 3, 2, 5, 4, 4, 2, 3, 3, 2, 3,\n",
              "                    5, 4, 4, 3, 3, 4, 4, 4, 4, 5, 2, 4, 5, 4, 5, 3, 5, 3,\n",
              "                    2, 5],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_n_estimators': masked_array(data=[353, 532, 573, 473, 391, 219, 308, 785, 799, 858, 677,\n",
              "                    471, 275, 721, 671, 824, 205, 911, 603, 586, 777, 315,\n",
              "                    709, 621, 532, 427, 658, 428, 445, 382, 828, 482, 294,\n",
              "                    262, 760, 885, 645, 396, 418, 783, 890, 317, 275, 265,\n",
              "                    625, 309, 930, 745, 130, 688, 315, 914, 245, 892, 172,\n",
              "                    566, 429, 323, 600, 456, 241, 151, 517, 405, 994, 361,\n",
              "                    718, 231, 512, 529, 756, 988, 102, 291, 446, 182, 577,\n",
              "                    262, 705, 147, 132, 941, 478, 514, 792, 162, 564, 484,\n",
              "                    986, 365, 492, 735, 289, 610, 579, 231, 453, 812, 797,\n",
              "                    192, 730, 845, 881, 658, 747, 999, 555, 889, 885, 855,\n",
              "                    851, 385, 696, 492, 751, 617, 797, 354, 739, 128, 314,\n",
              "                    292, 960, 437, 881, 723, 440, 442, 941, 480, 355, 738,\n",
              "                    922, 850, 705, 475, 594, 101, 473, 535, 478, 144, 567,\n",
              "                    905, 954, 359, 571, 774, 844, 538, 560, 848, 115, 327,\n",
              "                    322, 513, 863, 381, 594, 499, 796, 292, 330, 864, 888,\n",
              "                    558, 525, 639, 278, 172, 250, 395, 837, 436, 657, 228,\n",
              "                    643, 700, 534, 221, 971, 604, 796, 955, 758, 418, 761,\n",
              "                    524, 663, 135, 904, 333, 665, 973, 851, 620, 137, 652,\n",
              "                    998, 116],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_subsample': masked_array(data=[0.8633150151851346, 1.518747008099885,\n",
              "                    1.5569493362751168, 1.2060831843588289,\n",
              "                    0.6022592335185135, 1.0853774136627097,\n",
              "                    1.3645604503388786, 0.7162730174016898,\n",
              "                    1.071229778250014, 1.3331259776126707,\n",
              "                    0.9346475291060558, 1.5503135246995252,\n",
              "                    1.0066403018066616, 1.5951381603385584,\n",
              "                    1.0192502702591062, 0.9737231488239153,\n",
              "                    0.6842726697318456, 0.6279077888615325,\n",
              "                    0.6550199933402001, 0.6482187498255704,\n",
              "                    0.713601719539817, 1.0927373054365077,\n",
              "                    1.4947430739278906, 0.6611348560455946,\n",
              "                    1.4480156059904505, 1.1433145987328222,\n",
              "                    0.6179759626274195, 1.24410883687405,\n",
              "                    0.9794504577114115, 1.5574174237390572,\n",
              "                    1.4571905588319436, 1.5001034996569824,\n",
              "                    1.2429261484358456, 1.2108070555044093,\n",
              "                    0.669873674763088, 0.794674629042537,\n",
              "                    1.0028472101726735, 1.0190148274837505,\n",
              "                    0.9338324855146031, 0.7917107722555558,\n",
              "                    0.8538081939276894, 0.7263872837745974,\n",
              "                    1.2265293919225702, 0.9554429248010227,\n",
              "                    0.6080033397822812, 0.6846385203521214,\n",
              "                    0.8474754669724701, 1.2429332736267167,\n",
              "                    1.1928593606163143, 1.2593433507146705,\n",
              "                    1.5145908154415415, 1.5012986074730374,\n",
              "                    1.0255780251204425, 1.2103793515092094,\n",
              "                    0.7162057334478247, 1.2320315467138396,\n",
              "                    0.9219675875307266, 1.3434179682255138,\n",
              "                    1.5493815703849738, 0.6510386000250706,\n",
              "                    1.5053958666296534, 1.028661356516178,\n",
              "                    0.8598174877676139, 1.1213052583204295,\n",
              "                    1.5459781226700602, 1.3895761370422828,\n",
              "                    0.626287019886786, 0.6992046992760729,\n",
              "                    1.4447775859269387, 1.2033913951659096,\n",
              "                    1.3743069953206284, 1.4574259989933371,\n",
              "                    1.3211854061940067, 1.3724580748998283,\n",
              "                    0.8911074954680007, 1.278429829266097,\n",
              "                    0.7778132013791196, 1.0575829484147603,\n",
              "                    0.9637378187811511, 0.7861456200759936,\n",
              "                    0.7389402369520691, 0.9135039568356575,\n",
              "                    0.9488339716485302, 1.089308151441703,\n",
              "                    0.7100037748323762, 0.7444298281644256,\n",
              "                    1.3427790550190881, 1.3196175884244596,\n",
              "                    1.2545539998323858, 1.2765435155499492,\n",
              "                    0.6394834217756653, 1.40183299919891,\n",
              "                    1.0213942470646882, 0.972737943111001,\n",
              "                    0.8303270725601594, 1.2695639799794574,\n",
              "                    1.4721333282434506, 0.9189429381969031,\n",
              "                    1.2302115702366978, 1.059942206087201,\n",
              "                    1.0789612649136497, 1.1825452165868755,\n",
              "                    1.4441608139060667, 0.9455282442282628,\n",
              "                    1.1544596722588265, 0.9721481921431802,\n",
              "                    1.1292130273900813, 0.9946765200665661,\n",
              "                    0.6942454635533396, 0.8020169527201619,\n",
              "                    1.4541102417351135, 1.1051147612471262,\n",
              "                    1.5050829577983982, 0.9021506450318886,\n",
              "                    1.511307831526962, 0.6636046221722407,\n",
              "                    1.3396046033570541, 1.3284997282570092,\n",
              "                    1.3386971561501162, 0.7232801745447395,\n",
              "                    1.0595171267920205, 0.8934179965105292,\n",
              "                    1.4240099645738278, 0.7559694350390274,\n",
              "                    1.3995057337216088, 0.748573148891591,\n",
              "                    0.8116330125573674, 1.3660723991419141,\n",
              "                    0.7591357358522762, 1.1895883211368814,\n",
              "                    1.338462677787882, 1.1596896373689063,\n",
              "                    1.315740916604859, 1.4486721618941443,\n",
              "                    1.0706306579827625, 1.1867730010725128,\n",
              "                    1.2411315655900919, 1.5313555007806423,\n",
              "                    1.07350336340199, 1.10786772602459, 1.4155382653887234,\n",
              "                    1.5330412413240282, 0.9030629517893897,\n",
              "                    0.9932554927350794, 1.4404899875516601,\n",
              "                    1.0645693916825087, 1.0111898349808448,\n",
              "                    1.0742521086768142, 0.6959124054006526,\n",
              "                    0.6515952373879789, 1.2576556726273131,\n",
              "                    1.2222308511260835, 0.8243012512813312,\n",
              "                    0.9878757273165241, 1.3982304643804437,\n",
              "                    1.365620003122625, 0.6274991547177408,\n",
              "                    0.8062879903712816, 0.7423717857733823,\n",
              "                    1.3652287282732454, 0.7991574752332145,\n",
              "                    0.8970711552784341, 0.6828507727252764,\n",
              "                    1.2716385405659145, 0.9465884506699521,\n",
              "                    0.7370209576702677, 0.8919968214510806,\n",
              "                    1.4385669565781893, 1.494119525992125,\n",
              "                    0.9956526453280294, 1.2326534186157398,\n",
              "                    0.8590806711825623, 1.2018736416102922,\n",
              "                    1.1411778375385802, 1.5045176214579898,\n",
              "                    1.2177316417589839, 0.8419366424960035,\n",
              "                    0.817900517843144, 1.0825346800768805,\n",
              "                    1.0460456300029581, 1.213699832135513,\n",
              "                    0.6742267929580477, 1.2466637578587885,\n",
              "                    1.527489304008031, 0.8550048584140004,\n",
              "                    1.0937766364873582, 1.3284366401949912,\n",
              "                    1.0804062516102158, 1.3877370055878953,\n",
              "                    1.5790242837689554, 1.1950638333464885,\n",
              "                    0.6471626631365215, 1.0390378355367058,\n",
              "                    0.8776143076886695, 0.9064146294774575,\n",
              "                    1.0189955043672612, 1.3432940663714086,\n",
              "                    0.6649502472428793, 0.7507637702851822,\n",
              "                    1.5633881605368978],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'learning_rate': 0.05624885271390171,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 353,\n",
              "   'subsample': 0.8633150151851346},\n",
              "  {'learning_rate': 0.17012181801408932,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 532,\n",
              "   'subsample': 1.518747008099885},\n",
              "  {'learning_rate': 0.28021445623510366,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 573,\n",
              "   'subsample': 1.5569493362751168},\n",
              "  {'learning_rate': 0.05116279640682293,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 473,\n",
              "   'subsample': 1.2060831843588289},\n",
              "  {'learning_rate': 0.29326754081591266,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 391,\n",
              "   'subsample': 0.6022592335185135},\n",
              "  {'learning_rate': 0.16636780816608787,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 219,\n",
              "   'subsample': 1.0853774136627097},\n",
              "  {'learning_rate': 0.2404402462193267,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 308,\n",
              "   'subsample': 1.3645604503388786},\n",
              "  {'learning_rate': 0.01624293938561985,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 785,\n",
              "   'subsample': 0.7162730174016898},\n",
              "  {'learning_rate': 0.10296927534700877,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 799,\n",
              "   'subsample': 1.071229778250014},\n",
              "  {'learning_rate': 0.25485048941380806,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 858,\n",
              "   'subsample': 1.3331259776126707},\n",
              "  {'learning_rate': 0.2207867065765739,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 677,\n",
              "   'subsample': 0.9346475291060558},\n",
              "  {'learning_rate': 0.30341742370495567,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 471,\n",
              "   'subsample': 1.5503135246995252},\n",
              "  {'learning_rate': 0.2402426951861466,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 275,\n",
              "   'subsample': 1.0066403018066616},\n",
              "  {'learning_rate': 0.14539252342639428,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 721,\n",
              "   'subsample': 1.5951381603385584},\n",
              "  {'learning_rate': 0.06326925278136679,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 671,\n",
              "   'subsample': 1.0192502702591062},\n",
              "  {'learning_rate': 0.13721573396529962,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 824,\n",
              "   'subsample': 0.9737231488239153},\n",
              "  {'learning_rate': 0.1496524300517533,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 205,\n",
              "   'subsample': 0.6842726697318456},\n",
              "  {'learning_rate': 0.22975620944258504,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 911,\n",
              "   'subsample': 0.6279077888615325},\n",
              "  {'learning_rate': 0.10005101794719597,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 603,\n",
              "   'subsample': 0.6550199933402001},\n",
              "  {'learning_rate': 0.16697382123348756,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 586,\n",
              "   'subsample': 0.6482187498255704},\n",
              "  {'learning_rate': 0.1817213546588828,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 777,\n",
              "   'subsample': 0.713601719539817},\n",
              "  {'learning_rate': 0.09313516432755886,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 315,\n",
              "   'subsample': 1.0927373054365077},\n",
              "  {'learning_rate': 0.16196682270042845,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 709,\n",
              "   'subsample': 1.4947430739278906},\n",
              "  {'learning_rate': 0.19173330794067547,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 621,\n",
              "   'subsample': 0.6611348560455946},\n",
              "  {'learning_rate': 0.18755304773549927,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 532,\n",
              "   'subsample': 1.4480156059904505},\n",
              "  {'learning_rate': 0.23846197427839794,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 427,\n",
              "   'subsample': 1.1433145987328222},\n",
              "  {'learning_rate': 0.2963473340837451,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 658,\n",
              "   'subsample': 0.6179759626274195},\n",
              "  {'learning_rate': 0.17882114769884433,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 428,\n",
              "   'subsample': 1.24410883687405},\n",
              "  {'learning_rate': 0.09453584743514067,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 445,\n",
              "   'subsample': 0.9794504577114115},\n",
              "  {'learning_rate': 0.04881768730165729,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 382,\n",
              "   'subsample': 1.5574174237390572},\n",
              "  {'learning_rate': 0.13178750288789282,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 828,\n",
              "   'subsample': 1.4571905588319436},\n",
              "  {'learning_rate': 0.21667829980973727,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 482,\n",
              "   'subsample': 1.5001034996569824},\n",
              "  {'learning_rate': 0.28595946128869704,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 294,\n",
              "   'subsample': 1.2429261484358456},\n",
              "  {'learning_rate': 0.12556509407292224,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 262,\n",
              "   'subsample': 1.2108070555044093},\n",
              "  {'learning_rate': 0.18988575651920134,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 760,\n",
              "   'subsample': 0.669873674763088},\n",
              "  {'learning_rate': 0.2502202702646582,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 885,\n",
              "   'subsample': 0.794674629042537},\n",
              "  {'learning_rate': 0.07318229165586516,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 645,\n",
              "   'subsample': 1.0028472101726735},\n",
              "  {'learning_rate': 0.2755533083298385,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 396,\n",
              "   'subsample': 1.0190148274837505},\n",
              "  {'learning_rate': 0.20438775200177842,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 418,\n",
              "   'subsample': 0.9338324855146031},\n",
              "  {'learning_rate': 0.2435420301578034,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 783,\n",
              "   'subsample': 0.7917107722555558},\n",
              "  {'learning_rate': 0.13077674436878944,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 890,\n",
              "   'subsample': 0.8538081939276894},\n",
              "  {'learning_rate': 0.042845626399455654,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 317,\n",
              "   'subsample': 0.7263872837745974},\n",
              "  {'learning_rate': 0.19150161710906907,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 275,\n",
              "   'subsample': 1.2265293919225702},\n",
              "  {'learning_rate': 0.2078427861522449,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 265,\n",
              "   'subsample': 0.9554429248010227},\n",
              "  {'learning_rate': 0.11041722324303177,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 625,\n",
              "   'subsample': 0.6080033397822812},\n",
              "  {'learning_rate': 0.01313152062841634,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 309,\n",
              "   'subsample': 0.6846385203521214},\n",
              "  {'learning_rate': 0.10470047107859964,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 930,\n",
              "   'subsample': 0.8474754669724701},\n",
              "  {'learning_rate': 0.2657119887394419,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 745,\n",
              "   'subsample': 1.2429332736267167},\n",
              "  {'learning_rate': 0.28385378962223595,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 130,\n",
              "   'subsample': 1.1928593606163143},\n",
              "  {'learning_rate': 0.2026547894084684,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 688,\n",
              "   'subsample': 1.2593433507146705},\n",
              "  {'learning_rate': 0.05476710558031997,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 315,\n",
              "   'subsample': 1.5145908154415415},\n",
              "  {'learning_rate': 0.058771566247555376,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 914,\n",
              "   'subsample': 1.5012986074730374},\n",
              "  {'learning_rate': 0.2993998883890621,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 245,\n",
              "   'subsample': 1.0255780251204425},\n",
              "  {'learning_rate': 0.2846892586648913,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 892,\n",
              "   'subsample': 1.2103793515092094},\n",
              "  {'learning_rate': 0.061123509444032775,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 172,\n",
              "   'subsample': 0.7162057334478247},\n",
              "  {'learning_rate': 0.08398044343692729,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 566,\n",
              "   'subsample': 1.2320315467138396},\n",
              "  {'learning_rate': 0.038641076039461375,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 429,\n",
              "   'subsample': 0.9219675875307266},\n",
              "  {'learning_rate': 0.3013975881782734,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 323,\n",
              "   'subsample': 1.3434179682255138},\n",
              "  {'learning_rate': 0.1653067885106405,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 600,\n",
              "   'subsample': 1.5493815703849738},\n",
              "  {'learning_rate': 0.2865477864051653,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 456,\n",
              "   'subsample': 0.6510386000250706},\n",
              "  {'learning_rate': 0.24248206463041871,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 241,\n",
              "   'subsample': 1.5053958666296534},\n",
              "  {'learning_rate': 0.1863659454134808,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 151,\n",
              "   'subsample': 1.028661356516178},\n",
              "  {'learning_rate': 0.1989549936853421,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 517,\n",
              "   'subsample': 0.8598174877676139},\n",
              "  {'learning_rate': 0.20167392077864724,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 405,\n",
              "   'subsample': 1.1213052583204295},\n",
              "  {'learning_rate': 0.13734554166326585,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 994,\n",
              "   'subsample': 1.5459781226700602},\n",
              "  {'learning_rate': 0.30978209864327283,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 361,\n",
              "   'subsample': 1.3895761370422828},\n",
              "  {'learning_rate': 0.30447626640809106,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 718,\n",
              "   'subsample': 0.626287019886786},\n",
              "  {'learning_rate': 0.2339328283672442,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 231,\n",
              "   'subsample': 0.6992046992760729},\n",
              "  {'learning_rate': 0.16657080260714682,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 512,\n",
              "   'subsample': 1.4447775859269387},\n",
              "  {'learning_rate': 0.18346515174288117,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 529,\n",
              "   'subsample': 1.2033913951659096},\n",
              "  {'learning_rate': 0.24267118866382742,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 756,\n",
              "   'subsample': 1.3743069953206284},\n",
              "  {'learning_rate': 0.06812137782230138,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 988,\n",
              "   'subsample': 1.4574259989933371},\n",
              "  {'learning_rate': 0.10947340788886893,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 102,\n",
              "   'subsample': 1.3211854061940067},\n",
              "  {'learning_rate': 0.09751567743649978,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 291,\n",
              "   'subsample': 1.3724580748998283},\n",
              "  {'learning_rate': 0.23412719080414388,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 446,\n",
              "   'subsample': 0.8911074954680007},\n",
              "  {'learning_rate': 0.23724211468143708,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 182,\n",
              "   'subsample': 1.278429829266097},\n",
              "  {'learning_rate': 0.21066710448081444,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 577,\n",
              "   'subsample': 0.7778132013791196},\n",
              "  {'learning_rate': 0.1886447882845755,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 262,\n",
              "   'subsample': 1.0575829484147603},\n",
              "  {'learning_rate': 0.035331342419122704,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 705,\n",
              "   'subsample': 0.9637378187811511},\n",
              "  {'learning_rate': 0.11006834866486966,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 147,\n",
              "   'subsample': 0.7861456200759936},\n",
              "  {'learning_rate': 0.16577464142940812,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 132,\n",
              "   'subsample': 0.7389402369520691},\n",
              "  {'learning_rate': 0.1959798946951073,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 941,\n",
              "   'subsample': 0.9135039568356575},\n",
              "  {'learning_rate': 0.18078506721720575,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 478,\n",
              "   'subsample': 0.9488339716485302},\n",
              "  {'learning_rate': 0.12214258525865122,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 514,\n",
              "   'subsample': 1.089308151441703},\n",
              "  {'learning_rate': 0.11753928621543272,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 792,\n",
              "   'subsample': 0.7100037748323762},\n",
              "  {'learning_rate': 0.16280877155738682,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 162,\n",
              "   'subsample': 0.7444298281644256},\n",
              "  {'learning_rate': 0.14001506411569092,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 564,\n",
              "   'subsample': 1.3427790550190881},\n",
              "  {'learning_rate': 0.2799671419791405,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 484,\n",
              "   'subsample': 1.3196175884244596},\n",
              "  {'learning_rate': 0.17143062341398188,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 986,\n",
              "   'subsample': 1.2545539998323858},\n",
              "  {'learning_rate': 0.07989278286768985,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 365,\n",
              "   'subsample': 1.2765435155499492},\n",
              "  {'learning_rate': 0.19160358587677231,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 492,\n",
              "   'subsample': 0.6394834217756653},\n",
              "  {'learning_rate': 0.28163078643248757,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 735,\n",
              "   'subsample': 1.40183299919891},\n",
              "  {'learning_rate': 0.08376821318485123,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 289,\n",
              "   'subsample': 1.0213942470646882},\n",
              "  {'learning_rate': 0.12344741145434736,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 610,\n",
              "   'subsample': 0.972737943111001},\n",
              "  {'learning_rate': 0.1960012039852051,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 579,\n",
              "   'subsample': 0.8303270725601594},\n",
              "  {'learning_rate': 0.2948802497596223,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 231,\n",
              "   'subsample': 1.2695639799794574},\n",
              "  {'learning_rate': 0.0389948574639607,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 453,\n",
              "   'subsample': 1.4721333282434506},\n",
              "  {'learning_rate': 0.04205225304318569,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 812,\n",
              "   'subsample': 0.9189429381969031},\n",
              "  {'learning_rate': 0.18546066844878062,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 797,\n",
              "   'subsample': 1.2302115702366978},\n",
              "  {'learning_rate': 0.2847561207409351,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 192,\n",
              "   'subsample': 1.059942206087201},\n",
              "  {'learning_rate': 0.10472024653247086,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 730,\n",
              "   'subsample': 1.0789612649136497},\n",
              "  {'learning_rate': 0.08943552808187304,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 845,\n",
              "   'subsample': 1.1825452165868755},\n",
              "  {'learning_rate': 0.01640928407250194,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 881,\n",
              "   'subsample': 1.4441608139060667},\n",
              "  {'learning_rate': 0.014528841645520565,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 658,\n",
              "   'subsample': 0.9455282442282628},\n",
              "  {'learning_rate': 0.0464415134893934,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 747,\n",
              "   'subsample': 1.1544596722588265},\n",
              "  {'learning_rate': 0.148615110878552,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 999,\n",
              "   'subsample': 0.9721481921431802},\n",
              "  {'learning_rate': 0.268723047435508,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 555,\n",
              "   'subsample': 1.1292130273900813},\n",
              "  {'learning_rate': 0.21590640977167844,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 889,\n",
              "   'subsample': 0.9946765200665661},\n",
              "  {'learning_rate': 0.2633051778332585,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 885,\n",
              "   'subsample': 0.6942454635533396},\n",
              "  {'learning_rate': 0.07529742861844314,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 855,\n",
              "   'subsample': 0.8020169527201619},\n",
              "  {'learning_rate': 0.2518882077006919,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 851,\n",
              "   'subsample': 1.4541102417351135},\n",
              "  {'learning_rate': 0.2140731321521565,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 385,\n",
              "   'subsample': 1.1051147612471262},\n",
              "  {'learning_rate': 0.061999311954761785,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 696,\n",
              "   'subsample': 1.5050829577983982},\n",
              "  {'learning_rate': 0.08073960117229936,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 492,\n",
              "   'subsample': 0.9021506450318886},\n",
              "  {'learning_rate': 0.0629416985245142,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 751,\n",
              "   'subsample': 1.511307831526962},\n",
              "  {'learning_rate': 0.012764291154257059,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 617,\n",
              "   'subsample': 0.6636046221722407},\n",
              "  {'learning_rate': 0.29842454344375124,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 797,\n",
              "   'subsample': 1.3396046033570541},\n",
              "  {'learning_rate': 0.12731076484207993,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 354,\n",
              "   'subsample': 1.3284997282570092},\n",
              "  {'learning_rate': 0.2376838934371285,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 739,\n",
              "   'subsample': 1.3386971561501162},\n",
              "  {'learning_rate': 0.21029726316378608,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 128,\n",
              "   'subsample': 0.7232801745447395},\n",
              "  {'learning_rate': 0.09932693838735088,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 314,\n",
              "   'subsample': 1.0595171267920205},\n",
              "  {'learning_rate': 0.30963712266239174,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 292,\n",
              "   'subsample': 0.8934179965105292},\n",
              "  {'learning_rate': 0.3067231751139785,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 960,\n",
              "   'subsample': 1.4240099645738278},\n",
              "  {'learning_rate': 0.21124051782815792,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 437,\n",
              "   'subsample': 0.7559694350390274},\n",
              "  {'learning_rate': 0.17294892106120638,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 881,\n",
              "   'subsample': 1.3995057337216088},\n",
              "  {'learning_rate': 0.2681088847920134,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 723,\n",
              "   'subsample': 0.748573148891591},\n",
              "  {'learning_rate': 0.07244836588740568,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 440,\n",
              "   'subsample': 0.8116330125573674},\n",
              "  {'learning_rate': 0.2937184960719834,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 442,\n",
              "   'subsample': 1.3660723991419141},\n",
              "  {'learning_rate': 0.0930446196800168,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 941,\n",
              "   'subsample': 0.7591357358522762},\n",
              "  {'learning_rate': 0.24444283013583748,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 480,\n",
              "   'subsample': 1.1895883211368814},\n",
              "  {'learning_rate': 0.039937995385447046,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 355,\n",
              "   'subsample': 1.338462677787882},\n",
              "  {'learning_rate': 0.09515783134700735,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 738,\n",
              "   'subsample': 1.1596896373689063},\n",
              "  {'learning_rate': 0.26740379161352534,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 922,\n",
              "   'subsample': 1.315740916604859},\n",
              "  {'learning_rate': 0.2547614627866196,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 850,\n",
              "   'subsample': 1.4486721618941443},\n",
              "  {'learning_rate': 0.04756668042767664,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 705,\n",
              "   'subsample': 1.0706306579827625},\n",
              "  {'learning_rate': 0.2916251936998579,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 475,\n",
              "   'subsample': 1.1867730010725128},\n",
              "  {'learning_rate': 0.2539406776172024,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 594,\n",
              "   'subsample': 1.2411315655900919},\n",
              "  {'learning_rate': 0.059734107327166365,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 101,\n",
              "   'subsample': 1.5313555007806423},\n",
              "  {'learning_rate': 0.27919948090849256,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 473,\n",
              "   'subsample': 1.07350336340199},\n",
              "  {'learning_rate': 0.2741650905483195,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 535,\n",
              "   'subsample': 1.10786772602459},\n",
              "  {'learning_rate': 0.18975419418408254,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 478,\n",
              "   'subsample': 1.4155382653887234},\n",
              "  {'learning_rate': 0.09447708087862662,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 144,\n",
              "   'subsample': 1.5330412413240282},\n",
              "  {'learning_rate': 0.24634525135233942,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 567,\n",
              "   'subsample': 0.9030629517893897},\n",
              "  {'learning_rate': 0.05756507063771404,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 905,\n",
              "   'subsample': 0.9932554927350794},\n",
              "  {'learning_rate': 0.29075005729710646,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 954,\n",
              "   'subsample': 1.4404899875516601},\n",
              "  {'learning_rate': 0.21801854145736407,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 359,\n",
              "   'subsample': 1.0645693916825087},\n",
              "  {'learning_rate': 0.2799736624316611,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 571,\n",
              "   'subsample': 1.0111898349808448},\n",
              "  {'learning_rate': 0.28167694821880307,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 774,\n",
              "   'subsample': 1.0742521086768142},\n",
              "  {'learning_rate': 0.1283214484398384,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 844,\n",
              "   'subsample': 0.6959124054006526},\n",
              "  {'learning_rate': 0.2484051354086793,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 538,\n",
              "   'subsample': 0.6515952373879789},\n",
              "  {'learning_rate': 0.2505509857221751,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 560,\n",
              "   'subsample': 1.2576556726273131},\n",
              "  {'learning_rate': 0.23458353417705205,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 848,\n",
              "   'subsample': 1.2222308511260835},\n",
              "  {'learning_rate': 0.19123275845420215,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 115,\n",
              "   'subsample': 0.8243012512813312},\n",
              "  {'learning_rate': 0.058465285989949545,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 327,\n",
              "   'subsample': 0.9878757273165241},\n",
              "  {'learning_rate': 0.04646169458026819,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 322,\n",
              "   'subsample': 1.3982304643804437},\n",
              "  {'learning_rate': 0.11374775126970887,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 513,\n",
              "   'subsample': 1.365620003122625},\n",
              "  {'learning_rate': 0.029700205794900215,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 863,\n",
              "   'subsample': 0.6274991547177408},\n",
              "  {'learning_rate': 0.250506435172427,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 381,\n",
              "   'subsample': 0.8062879903712816},\n",
              "  {'learning_rate': 0.010766258943719789,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 594,\n",
              "   'subsample': 0.7423717857733823},\n",
              "  {'learning_rate': 0.27237623921442594,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 499,\n",
              "   'subsample': 1.3652287282732454},\n",
              "  {'learning_rate': 0.16507052034483924,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 796,\n",
              "   'subsample': 0.7991574752332145},\n",
              "  {'learning_rate': 0.11288792118523072,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 292,\n",
              "   'subsample': 0.8970711552784341},\n",
              "  {'learning_rate': 0.2026206671181647,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 330,\n",
              "   'subsample': 0.6828507727252764},\n",
              "  {'learning_rate': 0.17173595814417605,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 864,\n",
              "   'subsample': 1.2716385405659145},\n",
              "  {'learning_rate': 0.09455643649209249,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 888,\n",
              "   'subsample': 0.9465884506699521},\n",
              "  {'learning_rate': 0.08714651397562918,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 558,\n",
              "   'subsample': 0.7370209576702677},\n",
              "  {'learning_rate': 0.16694557398373805,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 525,\n",
              "   'subsample': 0.8919968214510806},\n",
              "  {'learning_rate': 0.23525633817775207,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 639,\n",
              "   'subsample': 1.4385669565781893},\n",
              "  {'learning_rate': 0.23378527332498122,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 278,\n",
              "   'subsample': 1.494119525992125},\n",
              "  {'learning_rate': 0.06056764548426611,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 172,\n",
              "   'subsample': 0.9956526453280294},\n",
              "  {'learning_rate': 0.025721274115610614,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 250,\n",
              "   'subsample': 1.2326534186157398},\n",
              "  {'learning_rate': 0.0969379750100206,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 395,\n",
              "   'subsample': 0.8590806711825623},\n",
              "  {'learning_rate': 0.10879062168130534,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 837,\n",
              "   'subsample': 1.2018736416102922},\n",
              "  {'learning_rate': 0.15114913326268967,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 436,\n",
              "   'subsample': 1.1411778375385802},\n",
              "  {'learning_rate': 0.20870098040549637,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 657,\n",
              "   'subsample': 1.5045176214579898},\n",
              "  {'learning_rate': 0.034264304999870446,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 228,\n",
              "   'subsample': 1.2177316417589839},\n",
              "  {'learning_rate': 0.086986052230001,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 643,\n",
              "   'subsample': 0.8419366424960035},\n",
              "  {'learning_rate': 0.23488056570003696,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 700,\n",
              "   'subsample': 0.817900517843144},\n",
              "  {'learning_rate': 0.08193274577359866,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 534,\n",
              "   'subsample': 1.0825346800768805},\n",
              "  {'learning_rate': 0.18406346426566375,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 221,\n",
              "   'subsample': 1.0460456300029581},\n",
              "  {'learning_rate': 0.03886931172759205,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 971,\n",
              "   'subsample': 1.213699832135513},\n",
              "  {'learning_rate': 0.05206557547946401,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 604,\n",
              "   'subsample': 0.6742267929580477},\n",
              "  {'learning_rate': 0.14469530951761306,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 796,\n",
              "   'subsample': 1.2466637578587885},\n",
              "  {'learning_rate': 0.12932248062620433,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 955,\n",
              "   'subsample': 1.527489304008031},\n",
              "  {'learning_rate': 0.07803716414192535,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 758,\n",
              "   'subsample': 0.8550048584140004},\n",
              "  {'learning_rate': 0.19655080977049633,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 418,\n",
              "   'subsample': 1.0937766364873582},\n",
              "  {'learning_rate': 0.2943313489749759,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 761,\n",
              "   'subsample': 1.3284366401949912},\n",
              "  {'learning_rate': 0.15329927673157298,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 524,\n",
              "   'subsample': 1.0804062516102158},\n",
              "  {'learning_rate': 0.08923074824717338,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 663,\n",
              "   'subsample': 1.3877370055878953},\n",
              "  {'learning_rate': 0.27527398830818844,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 135,\n",
              "   'subsample': 1.5790242837689554},\n",
              "  {'learning_rate': 0.2791045112137521,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 904,\n",
              "   'subsample': 1.1950638333464885},\n",
              "  {'learning_rate': 0.0989510082720107,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 333,\n",
              "   'subsample': 0.6471626631365215},\n",
              "  {'learning_rate': 0.22777447083744493,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 665,\n",
              "   'subsample': 1.0390378355367058},\n",
              "  {'learning_rate': 0.12934457973676097,\n",
              "   'max_depth': 4,\n",
              "   'n_estimators': 973,\n",
              "   'subsample': 0.8776143076886695},\n",
              "  {'learning_rate': 0.1934176541112144,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 851,\n",
              "   'subsample': 0.9064146294774575},\n",
              "  {'learning_rate': 0.23032246391680541,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 620,\n",
              "   'subsample': 1.0189955043672612},\n",
              "  {'learning_rate': 0.08905113900626711,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 137,\n",
              "   'subsample': 1.3432940663714086},\n",
              "  {'learning_rate': 0.03746859569921888,\n",
              "   'max_depth': 3,\n",
              "   'n_estimators': 652,\n",
              "   'subsample': 0.6649502472428793},\n",
              "  {'learning_rate': 0.048015082605498687,\n",
              "   'max_depth': 2,\n",
              "   'n_estimators': 998,\n",
              "   'subsample': 0.7507637702851822},\n",
              "  {'learning_rate': 0.2995100961952648,\n",
              "   'max_depth': 5,\n",
              "   'n_estimators': 116,\n",
              "   'subsample': 1.5633881605368978}],\n",
              " 'rank_test_score': array([ 31, 147, 148, 149,  11, 150, 151,  62, 152, 153,  69, 154, 155,\n",
              "        156, 157,  34,  18,  22,  75,   3,  59, 158, 159,  21, 160, 161,\n",
              "          6, 146,  55, 145, 144, 135, 129, 130,  16,  19, 131, 132,  68,\n",
              "         49,  32,  57, 133,  30,  42,  80,  58, 134, 136, 143, 137, 138,\n",
              "        139, 140,  77, 141,  65, 142, 162,  14, 164, 199,  50, 165, 184,\n",
              "        185,   2,   8, 186, 187, 188, 189, 190, 191,  29, 192,  46, 193,\n",
              "         61,  27,   5,  28,  37, 194,  10,  53, 195, 196, 197, 198,  81,\n",
              "        183, 182,  52,  54, 181, 172,  38, 166, 127, 167, 168, 169,  73,\n",
              "        170,  36, 171,  66,  79,  26, 173, 180, 174,  67, 175,  78, 176,\n",
              "        177, 178,  33, 179,  60, 128,  23, 163,  72,  20,  98,   9,  94,\n",
              "         93,  92,  91,  90, 100,  88,  86,  84,  83, 101, 125, 102,  43,\n",
              "         51, 119, 118, 117, 116,  64,   4, 112, 108,  39,  56,  82, 103,\n",
              "         15,  12,  74, 115,  24,  63,   7, 121,  45,  13,  35,  89,  95,\n",
              "         48, 126,  71,  97,  85, 122, 120,  41,  76, 111, 105, 104,  17,\n",
              "        106, 107,  40, 109, 110, 113, 114, 123, 124,   1,  87,  44,  25,\n",
              "         96,  99,  47,  70, 200], dtype=int32),\n",
              " 'split0_test_score': array([0.95924007,        nan,        nan,        nan, 0.9663219 ,\n",
              "               nan,        nan, 0.95464476,        nan,        nan,\n",
              "        0.95236931,        nan,        nan,        nan,        nan,\n",
              "        0.95915332, 0.96320395, 0.96084997, 0.94285479, 0.96713309,\n",
              "        0.9574351 ,        nan,        nan, 0.9619881 ,        nan,\n",
              "               nan, 0.96625073,        nan, 0.95776257,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.964107  ,\n",
              "        0.96233051,        nan,        nan, 0.95146971, 0.95843672,\n",
              "        0.95922639, 0.95744744,        nan, 0.95934887, 0.95978278,\n",
              "        0.96193602, 0.95721528,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.93914448,\n",
              "               nan, 0.95294067,        nan,        nan, 0.96413541,\n",
              "               nan,        nan, 0.95740041,        nan,        nan,\n",
              "               nan, 0.96764681, 0.9649449 ,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.95955723,\n",
              "               nan, 0.95845278,        nan, 0.95494631, 0.96042473,\n",
              "        0.96597015, 0.9597817 , 0.95927126,        nan, 0.96506906,\n",
              "        0.95756644,        nan,        nan,        nan,        nan,\n",
              "        0.92448402,        nan,        nan, 0.95762974, 0.95768707,\n",
              "               nan,        nan, 0.95882116,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.94482893,        nan,\n",
              "        0.95916877,        nan, 0.95290055, 0.94145782, 0.95995491,\n",
              "               nan,        nan,        nan, 0.95212249,        nan,\n",
              "        0.93712301,        nan,        nan,        nan, 0.95978134,\n",
              "               nan, 0.95527696,        nan, 0.96067378,        nan,\n",
              "        0.94737816, 0.96193031,        nan, 0.96501445,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.95919261, 0.9578741 ,        nan,\n",
              "               nan,        nan,        nan, 0.95385031, 0.96652146,\n",
              "               nan,        nan, 0.95894495, 0.9575797 ,        nan,\n",
              "               nan, 0.96413814, 0.9649336 , 0.94715585,        nan,\n",
              "        0.96001565, 0.95489749, 0.96524075,        nan, 0.95864723,\n",
              "        0.96521897, 0.95925156,        nan,        nan, 0.95794248,\n",
              "               nan, 0.94911041,        nan,        nan,        nan,\n",
              "               nan, 0.95877226, 0.94114642,        nan,        nan,\n",
              "               nan, 0.96339294,        nan,        nan, 0.95909529,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.96813544,        nan, 0.95837829, 0.95983033,\n",
              "               nan,        nan, 0.95877491, 0.94958505,        nan]),\n",
              " 'split1_test_score': array([0.99997542,        nan,        nan,        nan, 0.99964386,\n",
              "               nan,        nan, 0.99999078,        nan,        nan,\n",
              "        0.99986949,        nan,        nan,        nan,        nan,\n",
              "        0.9999572 , 0.9996793 , 0.99955624, 0.99944991, 0.99988284,\n",
              "        0.99973003,        nan,        nan, 0.99980668,        nan,\n",
              "               nan, 0.99933648,        nan, 0.99947132,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.99980304,\n",
              "        0.99990717,        nan,        nan, 0.99970502, 0.99993101,\n",
              "        0.99995254, 0.99995288,        nan, 0.99993926, 0.99983751,\n",
              "        0.99674346, 0.99995363,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.9995981 ,\n",
              "               nan, 0.9999617 ,        nan,        nan, 0.99979603,\n",
              "               nan,        nan, 0.99991649,        nan,        nan,\n",
              "               nan, 0.99978484, 0.99984726,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.99992641,\n",
              "               nan, 0.99987376,        nan, 0.99996928, 0.99993687,\n",
              "        0.99984155, 0.99994648, 0.99961549,        nan, 0.999937  ,\n",
              "        0.99959599,        nan,        nan,        nan,        nan,\n",
              "        0.99944854,        nan,        nan, 0.99989035, 0.99963909,\n",
              "               nan,        nan, 0.99998594,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.99997501,        nan,\n",
              "        0.99996156,        nan, 0.99997281, 0.9998361 , 0.99996414,\n",
              "               nan,        nan,        nan, 0.99954265,        nan,\n",
              "        0.99999202,        nan,        nan,        nan, 0.99941402,\n",
              "               nan, 0.99991536,        nan, 0.99982627,        nan,\n",
              "        0.99986764, 0.99996367,        nan, 0.99996095,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.99993586, 0.99979581,        nan,\n",
              "               nan,        nan,        nan, 0.99960841, 0.99982038,\n",
              "               nan,        nan, 0.99987967, 0.99966965,        nan,\n",
              "               nan, 0.99998831, 0.99957273, 0.99996843,        nan,\n",
              "        0.99970644, 0.99923189, 0.99984366,        nan, 0.99969812,\n",
              "        0.99995684, 0.99994056,        nan,        nan, 0.99997585,\n",
              "               nan, 0.99940698,        nan,        nan,        nan,\n",
              "               nan, 0.9998744 , 0.99987776,        nan,        nan,\n",
              "               nan, 0.99997096,        nan,        nan, 0.99989109,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.99992262,        nan, 0.99994851, 0.99994012,\n",
              "               nan,        nan, 0.99996244, 0.99981182,        nan]),\n",
              " 'split2_test_score': array([0.9938291 ,        nan,        nan,        nan, 0.99262988,\n",
              "               nan,        nan, 0.99385745,        nan,        nan,\n",
              "        0.99301531,        nan,        nan,        nan,        nan,\n",
              "        0.99382468, 0.99392271, 0.99425793, 0.9935134 , 0.99357854,\n",
              "        0.99348453,        nan,        nan, 0.99390617,        nan,\n",
              "               nan, 0.99377319,        nan, 0.99377246,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.99354191,\n",
              "        0.99358836,        nan,        nan, 0.99414199, 0.99303678,\n",
              "        0.99382893, 0.99345438,        nan, 0.99389248, 0.99277134,\n",
              "        0.96155405, 0.99352346,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.99390257,\n",
              "               nan, 0.99372656,        nan,        nan, 0.99388261,\n",
              "               nan,        nan, 0.99391778,        nan,        nan,\n",
              "               nan, 0.9937596 , 0.99396068,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.9937678 ,\n",
              "               nan, 0.99357971,        nan, 0.99378714, 0.99332574,\n",
              "        0.9938152 , 0.99380556, 0.9938365 ,        nan, 0.99363136,\n",
              "        0.99386787,        nan,        nan,        nan,        nan,\n",
              "        0.99355735,        nan,        nan, 0.99351409, 0.99369459,\n",
              "               nan,        nan, 0.99383107,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.99321443,        nan,\n",
              "        0.99366179,        nan, 0.99302749, 0.98816883, 0.99378997,\n",
              "               nan,        nan,        nan, 0.99371894,        nan,\n",
              "        0.99249531,        nan,        nan,        nan, 0.99378657,\n",
              "               nan, 0.99384412,        nan, 0.99368281,        nan,\n",
              "        0.99389527, 0.9938737 ,        nan, 0.9937503 ,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.99318658, 0.99352891,        nan,\n",
              "               nan,        nan,        nan, 0.99365286, 0.9937747 ,\n",
              "               nan,        nan, 0.99371939, 0.99361807,        nan,\n",
              "               nan, 0.99368403, 0.99407214, 0.99009039,        nan,\n",
              "        0.99414197, 0.99363952, 0.99400489,        nan, 0.9936692 ,\n",
              "        0.99311266, 0.9936964 ,        nan,        nan, 0.99385528,\n",
              "               nan, 0.99379741,        nan,        nan,        nan,\n",
              "               nan, 0.99384514, 0.99328252,        nan,        nan,\n",
              "               nan, 0.99383094,        nan,        nan, 0.99354637,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.99354963,        nan, 0.99382791, 0.99395372,\n",
              "               nan,        nan, 0.99307769, 0.99371548,        nan]),\n",
              " 'std_fit_time': array([1.94545817e-01, 2.59148764e-02, 4.24467433e-03, 3.76965373e-02,\n",
              "        6.18563953e-02, 2.44462026e-03, 2.80439945e-03, 2.07783712e-01,\n",
              "        6.23369366e-03, 9.36898037e-04, 1.03923231e-01, 5.58226051e-03,\n",
              "        1.49788530e-03, 3.92496882e-03, 6.47805639e-03, 4.00807576e-01,\n",
              "        3.94625490e-02, 1.05696238e-01, 8.61061753e-02, 1.27955297e-01,\n",
              "        5.91900789e-02, 1.01227199e-03, 2.86229608e-03, 1.10031903e-01,\n",
              "        1.78476900e-03, 4.39881196e-03, 1.84469849e-01, 3.23373700e-03,\n",
              "        6.47722425e-02, 7.41522081e-03, 9.46226149e-04, 7.49752198e-05,\n",
              "        5.11048413e-03, 5.05087492e-03, 1.36084337e-01, 1.70912141e-01,\n",
              "        2.86479293e-03, 1.42043427e-03, 3.92203737e-02, 1.70913340e-01,\n",
              "        5.92997564e-01, 9.18110717e-02, 1.45419704e-03, 1.79438419e-01,\n",
              "        1.62398138e-01, 1.81390763e-01, 5.20442127e-01, 7.84743523e-03,\n",
              "        9.47088289e-04, 5.71267925e-03, 5.82446228e-03, 6.03063801e-03,\n",
              "        5.62832097e-03, 2.57810496e-03, 2.68419180e-02, 3.94357889e-03,\n",
              "        1.67012516e-01, 8.20692077e-04, 3.68786304e-03, 8.42190649e-02,\n",
              "        4.60079617e-03, 4.91396141e-03, 9.82527709e-02, 1.01535790e-03,\n",
              "        3.75417003e-03, 5.33975178e-03, 1.93862659e-01, 8.55679592e-02,\n",
              "        7.22328957e-03, 6.90923924e-03, 3.09568198e-03, 9.95419829e-04,\n",
              "        2.71214740e-03, 5.08569504e-03, 2.37243148e-01, 5.47425009e-03,\n",
              "        9.84885313e-02, 2.87974338e-03, 2.80066330e-01, 7.39683219e-02,\n",
              "        6.43689014e-02, 4.43558370e-01, 8.56230559e-02, 4.72886915e-03,\n",
              "        4.84299955e-01, 4.78363893e-02, 4.65437550e-03, 1.14528955e-03,\n",
              "        5.70902258e-03, 1.31053228e-04, 6.84824535e-02, 2.04880686e-03,\n",
              "        4.34942826e-03, 1.86383787e-01, 9.27480366e-02, 5.91369530e-03,\n",
              "        2.76955353e-03, 4.70392379e-01, 3.66153148e-03, 3.41288175e-03,\n",
              "        5.74319858e-03, 3.89112939e-03, 3.86626600e-03, 1.94628291e-01,\n",
              "        5.13726050e-03, 4.58212029e-01, 5.48235387e-03, 9.35695590e-02,\n",
              "        1.44444816e-01, 4.71598498e-01, 4.89044058e-03, 1.26517132e-03,\n",
              "        7.06232548e-03, 1.01577430e-01, 1.27382628e-03, 1.16163051e-01,\n",
              "        4.79227473e-03, 5.76799062e-03, 6.55925363e-03, 2.71402974e-02,\n",
              "        3.39820684e-03, 2.77296458e-02, 1.50275436e-03, 1.17359914e-01,\n",
              "        2.84378229e-03, 1.92919435e-01, 2.57509078e-01, 3.22997419e-03,\n",
              "        6.77227205e-01, 5.28221758e-03, 2.71445378e-03, 5.52160880e-03,\n",
              "        5.24500328e-03, 4.35963225e-03, 3.35790010e-03, 4.88546411e-04,\n",
              "        7.06856774e-03, 4.95219060e-03, 5.89339716e-03, 4.73293068e-03,\n",
              "        3.85820809e-03, 6.36921593e-03, 2.81880401e-01, 1.75506335e-01,\n",
              "        3.07072532e-03, 1.46817108e-03, 4.37117728e-03, 1.57477730e-03,\n",
              "        1.11066199e-01, 1.61164093e-01, 2.13685482e-03, 6.82438828e-03,\n",
              "        7.71887071e-02, 4.85011823e-02, 4.07667395e-03, 4.18898395e-03,\n",
              "        4.00010655e-01, 4.93284162e-02, 1.38660459e-01, 1.42690990e-03,\n",
              "        9.28829542e-02, 3.69803727e-02, 2.08190978e-01, 1.27937108e-03,\n",
              "        1.40595886e-01, 2.46703875e-01, 3.46243933e-01, 5.67210420e-03,\n",
              "        9.49714094e-04, 9.67593244e-02, 1.39252919e-03, 9.12502371e-02,\n",
              "        6.69076203e-03, 5.35497733e-03, 8.96457542e-04, 2.19055298e-03,\n",
              "        1.65240640e-01, 1.39923652e-01, 5.82579871e-03, 2.90358096e-03,\n",
              "        1.04556058e-03, 2.95064236e-01, 5.62049189e-03, 4.02272320e-04,\n",
              "        2.38864857e-01, 3.60537540e-03, 2.95373233e-03, 4.50130513e-03,\n",
              "        3.79258185e-03, 4.88645119e-04, 3.19425764e-03, 1.37584090e-01,\n",
              "        1.60062088e-04, 1.83746052e-01, 4.63927661e-01, 3.91011401e-03,\n",
              "        5.98262062e-03, 1.38233674e-01, 3.67150141e+00, 1.71625143e-03]),\n",
              " 'std_score_time': array([0.01945711, 0.        , 0.        , 0.        , 0.02459124,\n",
              "        0.        , 0.        , 0.05359436, 0.        , 0.        ,\n",
              "        0.02273785, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.07420801, 0.01037722, 0.03671935, 0.01826606, 0.05313615,\n",
              "        0.03723171, 0.        , 0.        , 0.02873708, 0.        ,\n",
              "        0.        , 0.02774858, 0.        , 0.01658867, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.04175721,\n",
              "        0.04455012, 0.        , 0.        , 0.01165091, 0.04527729,\n",
              "        0.10659253, 0.01082334, 0.        , 0.0095783 , 0.04017349,\n",
              "        0.00958706, 0.08087238, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.00135393,\n",
              "        0.        , 0.01643351, 0.        , 0.        , 0.05365403,\n",
              "        0.        , 0.        , 0.03955134, 0.        , 0.        ,\n",
              "        0.        , 0.05816058, 0.02179878, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.04218672,\n",
              "        0.        , 0.02671118, 0.        , 0.02865785, 0.01441314,\n",
              "        0.00747162, 0.08651188, 0.01410066, 0.        , 0.09006301,\n",
              "        0.00962746, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.02089573, 0.        , 0.        , 0.02489128, 0.02275343,\n",
              "        0.        , 0.        , 0.04451133, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.01625805, 0.        ,\n",
              "        0.07121958, 0.        , 0.03355768, 0.05251106, 0.05125508,\n",
              "        0.        , 0.        , 0.        , 0.01521367, 0.        ,\n",
              "        0.0194643 , 0.        , 0.        , 0.        , 0.00578453,\n",
              "        0.        , 0.00806771, 0.        , 0.01817237, 0.        ,\n",
              "        0.02077643, 0.03179307, 0.        , 0.06217607, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.05876015, 0.03167633, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.03393638, 0.03037203,\n",
              "        0.        , 0.        , 0.00883562, 0.00735847, 0.        ,\n",
              "        0.        , 0.05709514, 0.01025051, 0.02942803, 0.        ,\n",
              "        0.02657574, 0.00679499, 0.0331239 , 0.        , 0.02973573,\n",
              "        0.05445822, 0.05174607, 0.        , 0.        , 0.01000633,\n",
              "        0.        , 0.00988264, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.02442697, 0.04034563, 0.        , 0.        ,\n",
              "        0.        , 0.03892866, 0.        , 0.        , 0.03539416,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.02187231, 0.        , 0.06815806, 0.04567375,\n",
              "        0.        , 0.        , 0.03090011, 0.08867298, 0.        ]),\n",
              " 'std_test_score': array([0.01793057,        nan,        nan,        nan, 0.01434364,\n",
              "               nan,        nan, 0.02008735,        nan,        nan,\n",
              "        0.02096384,        nan,        nan,        nan,        nan,\n",
              "        0.01796499, 0.01601122, 0.01713456, 0.02539585, 0.01418784,\n",
              "        0.01864114,        nan,        nan, 0.01661266,        nan,\n",
              "               nan, 0.01446491,        nan, 0.01846561,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.01556286,\n",
              "        0.01642825,        nan,        nan, 0.02154715, 0.0181551 ,\n",
              "        0.01793028, 0.01869475,        nan, 0.01788048, 0.01745647,\n",
              "        0.01649915, 0.01881547,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.02725502,\n",
              "               nan, 0.02085224,        nan,        nan, 0.01560464,\n",
              "               nan,        nan, 0.01878865,        nan,        nan,\n",
              "               nan, 0.01394845, 0.01525612,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.01775751,\n",
              "               nan, 0.01822457,        nan, 0.01992736, 0.01728002,\n",
              "        0.01475329, 0.01766523, 0.01781326,        nan, 0.01517066,\n",
              "        0.0186103 ,        nan,        nan,        nan,        nan,\n",
              "        0.03403513,        nan,        nan, 0.01860198, 0.0185348 ,\n",
              "               nan,        nan, 0.01812952,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.02455821,        nan,\n",
              "        0.01793044,        nan, 0.02074771, 0.0252236 , 0.01758683,\n",
              "               nan,        nan,        nan, 0.02111569,        nan,\n",
              "        0.02803728,        nan,        nan,        nan, 0.01750801,\n",
              "               nan, 0.01976774,        nan, 0.01719256,        nan,\n",
              "        0.02346311, 0.01668001,        nan, 0.01522271,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.01782992, 0.01846309,        nan,\n",
              "               nan,        nan,        nan, 0.02031287, 0.01448412,\n",
              "               nan,        nan, 0.01802117, 0.01858001,        nan,\n",
              "               nan, 0.01562739, 0.01519934, 0.02292529,        nan,\n",
              "        0.01754653, 0.01971395, 0.01512477,        nan, 0.01809869,\n",
              "        0.0150245 , 0.01789175,        nan,        nan, 0.01854123,\n",
              "               nan, 0.02250467,        nan,        nan,        nan,\n",
              "               nan, 0.01812256, 0.02627005,        nan,        nan,\n",
              "               nan, 0.01599348,        nan,        nan, 0.017924  ,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.01373123,        nan, 0.01832491, 0.01766679,\n",
              "               nan,        nan, 0.01801386, 0.02237903,        nan])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYvVj159I7C7"
      },
      "source": [
        "**Print the top 5 results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1p6G6OtzGHTE",
        "outputId": "b1143b8a-ab7f-429d-9b52-8f8fd853fa0a"
      },
      "source": [
        "import numpy as np\n",
        "results = search.cv_results_\n",
        "for i in range(1, 5):\n",
        "  candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
        "  for candidate in candidates:\n",
        "      print(\"Model with rank: {0}\".format(i))\n",
        "      print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
        "            results['mean_test_score'][candidate],\n",
        "            results['std_test_score'][candidate]))\n",
        "      print(\"Parameters: {0}\".format(results['params'][candidate]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model with rank: 1\n",
            "Mean validation score: 0.987 (std: 0.014)\n",
            "Parameters: {'learning_rate': 0.0989510082720107, 'max_depth': 4, 'n_estimators': 333, 'subsample': 0.6471626631365215}\n",
            "Model with rank: 2\n",
            "Mean validation score: 0.987 (std: 0.014)\n",
            "Parameters: {'learning_rate': 0.30447626640809106, 'max_depth': 4, 'n_estimators': 718, 'subsample': 0.626287019886786}\n",
            "Model with rank: 3\n",
            "Mean validation score: 0.987 (std: 0.014)\n",
            "Parameters: {'learning_rate': 0.16697382123348756, 'max_depth': 4, 'n_estimators': 586, 'subsample': 0.6482187498255704}\n",
            "Model with rank: 4\n",
            "Mean validation score: 0.987 (std: 0.014)\n",
            "Parameters: {'learning_rate': 0.2484051354086793, 'max_depth': 4, 'n_estimators': 538, 'subsample': 0.6515952373879789}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQb2CT6mlLtB"
      },
      "source": [
        "### **Print the best params**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIwpz4uYI2Rd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd2257ca-96cc-4e19-9c3b-779c049ebb58"
      },
      "source": [
        "params_best = search.best_params_\n",
        "params_best"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'learning_rate': 0.0989510082720107,\n",
              " 'max_depth': 4,\n",
              " 'n_estimators': 333,\n",
              " 'subsample': 0.6471626631365215}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJ3vj9mhrWq9"
      },
      "source": [
        "### **Load the best params and print the results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SZIt9H6dJXQ",
        "outputId": "8c383818-c489-4733-eb40-61879b9f59ad"
      },
      "source": [
        "params = {'learning_rate': 0.0989510082720107,\n",
        "          'max_depth': 4,\n",
        "          'n_estimators': 333,\n",
        "          'subsample': 0.6471626631365215}\n",
        "\n",
        "xgb_model = xgb.XGBRegressor(**params)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "text_pred = xgb_model.predict(X_test)\n",
        "train_pred = xgb_model.predict(X_train)\n",
        "\n",
        "\n",
        "print('Test set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_test, text_pred)\n",
        "print('Train set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_train, train_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[00:39:45] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Test set evaluation:\n",
            "_____________________________________\n",
            "MAE: 180.9494020464025\n",
            "MSE: 290654.3473780277\n",
            "RMSE: 539.1236846754441\n",
            "R2 Square 0.9999151164550641\n",
            "Train set evaluation:\n",
            "_____________________________________\n",
            "MAE: 146.89486534387223\n",
            "MSE: 46529.69595010651\n",
            "RMSE: 215.70743137431893\n",
            "R2 Square 0.9999864986342818\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}